<!DOCTYPE html>

<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Live input record and playback</title>
  <style type='text/css'>
    ul { list-style: none; }
    #recordingslist audio { display: block; margin-bottom: 10px; }
  </style>
  <!-- <script src="/socket.io/socket.io.js"></script> -->
  <script src="http://127.0.0.1:3000/socket.io/socket.io.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
</head>
<body>

  <h1>Recorder.js simple WAV export example</h1>
  <p>Make sure you are using a recent version of Google Chrome, at the moment this only works with Google Chrome Canary.</p>
  <p>Also before you enable microphone input either plug in headphones or turn the volume down if you want to avoid ear splitting feedback!</p>

  <button id="broadcastInfo">廣播狀態</button>
  <button id="broadcastStart">開始廣播</button>
  <button id="broadcastStop">停止廣播</button>

  <h2>Recordings</h2>
  <ul id="recordingslist"></ul>

  <h2>Log</h2>
  <pre id="log"></pre>

  <script>
    var broadcast_socket

    $('#broadcastInfo').click(() => {
      $.get('http://127.0.0.1:3000/api/broadcast/info', res => {
        log.innerHTML += "\n" + `Status: ${res.status},    Area: ${JSON.stringify(res.area)}`;
      })
    })

    $("#broadcastStart").click(function(){
      $.post('http://127.0.0.1:3000/api/broadcast/start', {
        type: 'ws',
        area: [],
        address: '192.168.0.1'
      }, function(data){
        if (data.message === 'OK') {
          // 後端通知成功後，連上後端廣播用的 ws
          broadcast_socket = new WebSocket('ws://localhost:8000');
          broadcast_socket.binaryType = 'arraybuffer'

          // 連上後端廣播用的 ws 後，開始錄音，並送資料
          broadcast_socket.onopen = function () {
            console.log(broadcast_socket);
            console.log('connect');
            startRecording()
            // setInterval(() => {
            //   broadcast_socket.send('打招呼')  // broadcast 使用者送資料
            // }, 1000)
          }
        } else {
          alert(data.message)
        }
      });
    });

    $("#broadcastStop").click(function(){
      stopRecording()
      $.get(`http://127.0.0.1:3000/api/broadcast/stop`, () => {
        if (broadcast_socket) broadcast_socket.close()
        broadcast_socket = null
      })
    })

  </script>

<script>
  function __log(e, data) {
    log.innerHTML += "\n" + e + " " + (data || '')
  }

  var audio_context
  var recorder
  let mediaRecorder
  let chunks = []

  function startRecording() {
    recorder && recorder.record()  // recorder 收聲音串流
    __log('Recording...')

    // mediaRecorder.start()
  }

  function stopRecording() {
    recorder && recorder.stop()
    __log('Stopped recording.')

    // mediaRecorder.stop();

    // create WAV download link using audio data blob
    // createDownloadLink();
    
    recorder.clear()
  }

  function createDownloadLink() {
    recorder && recorder.exportWAV(function(blob) {
      var url = URL.createObjectURL(blob);
      var li = document.createElement('li');
      var au = document.createElement('audio');
      var hf = document.createElement('a');
      au.controls = true;
      au.src = url;
      hf.href = url;
      hf.download = new Date().toISOString() + '.wav';
      hf.innerHTML = hf.download;
      li.appendChild(au);
      li.appendChild(hf);
      recordingslist.appendChild(li);
    });
  }

  window.onload = function init() {
    try {
      // webkit shim
      window.AudioContext = window.AudioContext || window.webkitAudioContext
      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia
      window.URL = window.URL || window.webkitURL

      audio_context = new AudioContext;
      __log('Audio context set up.')
      __log('navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'))
    } catch (e) {
      alert('No web audio support in this browser!')
    }

    // 詢問使用者是否可使用其媒體設備
    navigator.mediaDevices.getUserMedia({audio: true})
      .then(stream => _startUserMedia(stream))
      .catch(err => __log(err))

    function _startUserMedia(stream) {
      var input = audio_context.createMediaStreamSource(stream)  // 利用 createMediaStreamSource 將麥克風音訊轉成音源節點
      __log('Media stream created.')

      // 初始化 MediaRecorder 物件：用來分析聲音節點。初始化時可以提供初始化參數，例如 mimeType, sampleRate
      // mediaRecorder = new MediaRecorder(stream)

      // input.connect(audio_context.destination);  // 將 input 傳送到指定位置
      // __log('Input connected to audio context destination.')

      // 初始化 recorder.js 物件，並將音源節點傳入
      recorder = new Recorder(input)
      __log('Recorder initialised.')
    }
  }

  </script>
  <script src="recorder.js"></script>

  <script src="socket_io.js"></script>
</body>
</html>
